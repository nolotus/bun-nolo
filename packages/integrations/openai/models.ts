// integrations/openai/models.ts
import type { Model } from "ai/llm/types";

export const openAIModels: Model[] = [
  {
    name: "gpt-4.1",
    displayName: "GPT-4.1",
    hasVision: true,
    contextWindow: 1_047_576,
    maxOutputTokens: 32_768,
    supportsReasoningEffort: false,
    price: { input: 20, output: 80, inputCacheHit: 50 },
  },
  {
    name: "gpt-4.1-mini",
    displayName: "GPT-4.1 Mini",
    hasVision: true,
    contextWindow: 1_047_576,
    maxOutputTokens: 32_768,
    supportsReasoningEffort: false,
    price: { input: 3.2, output: 12.8, inputCacheHit: 0.8 },
  },
  {
    name: "gpt-4.1-nano",
    displayName: "GPT-4.1 Nano",
    hasVision: true,
    contextWindow: 1_047_576,
    maxOutputTokens: 32_768,
    supportsReasoningEffort: false,
    price: { input: 0.8, output: 3.2, inputCacheHit: 0.2 },
  },
  {
    name: "o3-pro",
    displayName: "O3 Pro",
    hasVision: false,
    contextWindow: 200_000,
    maxOutputTokens: 100_000,
    supportsReasoningEffort: true,
    endpointKey: "responses",
    price: { input: 200, output: 800, inputCacheHit: 0 },
  },
  {
    name: "o3",
    displayName: "O3",
    hasVision: false,
    contextWindow: 200_000,
    maxOutputTokens: 100_000,
    supportsReasoningEffort: true,
    price: { input: 20, output: 80, inputCacheHit: 5 },
  },
  {
    name: "o4-mini",
    displayName: "O4 Mini",
    hasVision: false,
    contextWindow: 200_000,
    maxOutputTokens: 100_000,
    supportsReasoningEffort: true,
    endpointKey: "responses",
    price: { input: 11, output: 44, inputCacheHit: 2.8 },
  },
];
