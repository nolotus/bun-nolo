import { NoloRootState } from "app/store";
import { generatePrompt } from "ai/prompt/generatePrompt";
import { selectAllMsgs } from "chat/messages/messageSlice";
import { filterAndCleanMessages } from "integrations/openai/filterAndCleanMessages";

// ç±»å‹å®šä¹‰ä¿æŒä¸å˜...
type MessageContentPartText = { type: "text"; text: string };
type MessageContentPartImageUrl = {
  type: "image_url";
  image_url: { url: string; detail?: "low" | "high" | "auto" };
};
type MessageContentPart = MessageContentPartText | MessageContentPartImageUrl;
interface Message {
  role: "user" | "assistant" | "system" | "tool";
  content: string | MessageContentPart[];
  name?: string;
  tool_calls?: any;
  tool_call_id?: string;
}
interface BuildRequestBodyOptions {
  model: string;
  messages: Message[];
  providerName: string;
  temperature?: number;
  top_p?: number;
  frequency_penalty?: number;
  presence_penalty?: number;
  max_tokens?: number;
  reasoning_effort?: string;
}
// ğŸ‘‡ æ–°å¢ contexts ç±»å‹
interface Contexts {
  currentUserContext?: string | null;
  smartReadContext?: string | null;
  historyContext?: string | null;
  preConfiguredContext?: string | null;
}

/**
 * åœ¨æ¶ˆæ¯åˆ—è¡¨å‰æ·»åŠ ç³»ç»Ÿæç¤º
 */
const prependPromptMessage = (
  messages: Message[],
  prompt: string | undefined,
  botName: string | undefined,
  language: string,
  contexts: Contexts // ğŸ‘ˆ æ¥æ”¶ç»“æ„åŒ– contexts
): Message[] => {
  const promptContent = generatePrompt({
    prompt,
    name: botName,
    language,
    contexts, // ğŸ‘ˆ ç›´æ¥ä¼ é€’ contexts å¯¹è±¡
  });

  if (promptContent.trim()) {
    const systemMessage: Message = { role: "system", content: promptContent };
    return [systemMessage, ...messages];
  }
  return messages;
};

/**
 * åªä¼ å¿…è¦å­—æ®µï¼Œæ„å»ºè¯·æ±‚ä½“ (æ­¤å‡½æ•°ä¿æŒä¸å˜)
 */
const buildRequestBody = (options: BuildRequestBodyOptions): any => {
  const {
    model,
    messages,
    providerName,
    temperature,
    top_p,
    frequency_penalty,
    presence_penalty,
    max_tokens,
    reasoning_effort,
  } = options;

  const bodyData: any = {
    model,
    messages,
    stream: true,
  };

  // Provider-specific options
  if (
    ["google", "openrouter", "xai", "openai", "deepinfra"].includes(
      providerName
    )
  ) {
    bodyData.stream_options = { include_usage: true };
  }

  // é€šç”¨çš„ reasoning_effort å¤„ç†
  if (reasoning_effort) {
    bodyData.reasoning_effort = reasoning_effort;
  }

  if (typeof temperature === "number") bodyData.temperature = temperature;
  if (typeof top_p === "number") bodyData.top_p = top_p;
  if (typeof frequency_penalty === "number")
    bodyData.frequency_penalty = frequency_penalty;
  if (typeof presence_penalty === "number")
    bodyData.presence_penalty = presence_penalty;
  if (typeof max_tokens === "number") bodyData.max_tokens = max_tokens;

  return bodyData;
};

/**
 * ä¸»å‡½æ•°
 * ğŸ‘‡ ä¿®æ”¹å‡½æ•°ç­¾åä»¥æ¥æ”¶ contexts å¯¹è±¡
 */
export const generateOpenAIRequestBody = (
  state: NoloRootState,
  cybotConfig: {
    model: string;
    prompt?: string;
    name?: string;
    temperature?: number;
    top_p?: number;
    frequency_penalty?: number;
    presence_penalty?: number;
    max_tokens?: number;
    reasoning_effort?: string;
    [key: string]: any;
  },
  providerName: string,
  contexts: Contexts // ğŸ‘ˆ æ¥æ”¶ç»“æ„åŒ– contexts
) => {
  // 1. è·å–æ¸…ç†å†å²æ¶ˆæ¯
  const previousMessages = filterAndCleanMessages(selectAllMsgs(state));

  // 2. æ¶ˆæ¯é˜Ÿå¤´æ’å…¥ prompt
  const messagesWithPrompt = prependPromptMessage(
    previousMessages,
    cybotConfig.prompt,
    cybotConfig.name,
    navigator.language,
    contexts // ğŸ‘ˆ ä¼ é€’ contexts å¯¹è±¡
  );

  // 3. æ„å»ºè¯·æ±‚ä½“
  const requestBody = buildRequestBody({
    model: cybotConfig.model,
    messages: messagesWithPrompt,
    providerName,
    temperature: cybotConfig.temperature,
    top_p: cybotConfig.top_p,
    frequency_penalty: cybotConfig.frequency_penalty,
    presence_penalty: cybotConfig.presence_penalty,
    max_tokens: cybotConfig.max_tokens,
    reasoning_effort: cybotConfig.reasoning_effort,
  });

  return requestBody;
};
